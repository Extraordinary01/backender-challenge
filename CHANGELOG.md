# Тестовое задание Improvado

### Внесённые изменения в настройки проекта
Добавил в `docker-compose.yml` изображения с celery, celery-beat так как они нужны для фонового отправления ивентов в ClickHouse.
В requirements.txt добавил новую зависимость redis, для взаимодействия с редисом. Также изменил команду run (сделал так чтобы контейнеры
запускались в бэкграунде) и добавил stop для остановки контейнеров в `Makefile`. Добавил переменные для редиса в `.env.ci`. В остальном
ничего не изменил.


### Реализация
Для решения всех описанных проблем я использую очередь в редисе, это очень простое решение и практически 100 процентно гарантирует
доставку данных. Можно было использовать стримы, но решил сделать по-проще. При записи ивента, мы его сначала записываем в очередь редиса.
Селери таска проверяет, если размер очереди превысил максимум или время с последнего отправки данных прошел разрешенный таймаут, то мы
начинаем новую отправку данных в ClickHouse. Мы берем из очереди все ивенты и отправляем их в CH. Таким образом проблем большого количества
записей тоже убирается. Насчёт сетевых ошибок думаю тоже, проблема разрешена, учитывая что мы добавили блоки try..except (или я не так понял).

Насчёт упрощения реализации не уверен, что нужно было упрощать. В добавленном исходнике итак, всё было написано достаточно просто. В классе
EventLogClient я добавил новые методы для реализации взаимодействия с редисом. Возможно это покажется "не простым" решением, но по факту при
использовании, мы будем пользоваться только методом `log_event`. Можно было бы реализовать метод `init` не ContextManager, а как нибудь по другому,
так как в большинстве кейсов такое использования может быть не удобным. Для текущей ситуации вполне сгодиться.

Насчёт повторного использования момент не понял, причём тут Celery, если для неё даже не одной таски не существует.
Текущая реализация класса EventLogClient, мне кажется не допускает в себе дублирования.

При тестировании я просто убрал последний тест, который тестировал работу старой логики логирования. И заменил её новой, где мы
проверяем, что сначала данные отправляются на хранение в редис. А после выполнения условия с таймаутом, мы уже добавляем их в
ClickHouse. За один тест, как по мне я проверил работу новой логики. Можно ещё добавить тест, когда рейзиться ошибка во время добавления
данных в CH. Тогда мы добавляем не добавленные ивенты, в дополнительную очередь. После отдельная селери таска будет пытаться заново добавить
эти данные в CH. При второй не удаче скорее всего будет проблема в самих данных и в таком случае мы не будем пытаться добавлять их повторно.
Данную логику можно сделать как угодно в зависимости от условий и есть множество способов реализации ошибочного сценария.


### От автора
Надеюсь я смог выполнить все требования, хотя в этом у меня есть сомнения, так как были моменты где я не до понял.
Но надеюсь данная реализация убедит вас в моих способностях. Хочу отметить, что у меня до этого опыта с ClickHouse, Pydantic и
Structlog не было. Поэтому с библиотекой питона и с запросами в CH особо не игрался. Также насчёт Sentry. В настройках оно уже интегрировано
с джангой и селери. В таком случае, Sentry будет автоматически отлавливать ошибки, поэтому не посчитал нужным где-либо что-то добавить для
этих целей.